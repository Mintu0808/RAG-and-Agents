{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf313fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb1cdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 221 pages from PDF.\n",
      "SQL\n",
      "#sql\n",
      "Steve Nouri\n",
      "{'producer': 'GPL Ghostscript 9.52', 'creator': '', 'creationdate': '2020-08-06T08:33:49+02:00', 'source': 'data/learn_sql.pdf', 'file_path': 'data/learn_sql.pdf', 'total_pages': 221, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2020-08-06T08:33:49+02:00', 'trapped': '', 'encryption': 'Standard V2 R3 128-bit RC4', 'modDate': \"D:20200806083349+02'00'\", 'creationDate': \"D:20200806083349+02'00'\", 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "pdf_data = PyMuPDFLoader(\"data/learn_sql.pdf\").load()\n",
    "print(f\"Loaded {len(pdf_data)} pages from PDF.\")\n",
    "print(pdf_data[0].page_content[:500])  # Print first 500 characters of the first page\n",
    "print(pdf_data[0].metadata)  # Print metadata of the first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3be8db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class smartPDFProcessor:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "                                                             chunk_overlap=20,\n",
    "                                                             separators=[\" \"])\n",
    "\n",
    "    def process(self, pdf_path):\n",
    "        # Split the PDF content into manageable chunks\n",
    "        self.pdf_data = PyMuPDFLoader(pdf_path).load()\n",
    "        print(f\"Loaded {len(self.pdf_data)} pages from PDF.\")\n",
    "        chunks = self.text_splitter.split_documents(self.pdf_data)\n",
    "        print(f\"Processed into {len(chunks)} chunks.\")\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71d553d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 221 pages from PDF.\n",
      "Processed into 354 chunks.\n"
     ]
    }
   ],
   "source": [
    "process_text = smartPDFProcessor()\n",
    "doc_chunk = process_text.process(\"data/learn_sql.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e9653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
